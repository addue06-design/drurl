import asyncio
import re
import os
from playwright.async_api import async_playwright

# --- è¨­å®šå€åŸŸ ---
# å¦‚æœæ˜¯æ•¸å­—ï¼Œç³»çµ±æœƒç›´æ¥é€²å…¥ä»£ç¢¼æ¨¡å¼ï¼›å¦‚æœæ˜¯æ–‡å­—ï¼Œæœƒå» /all/ æœå°‹
TARGET_INPUT = "202500838"  
DOMAIN = "dramaq.xyz" # å»ºè­°ä½¿ç”¨ä¸»ç«™æœå°‹
# ------------------

async def get_m3u8_for_ep(page, drama_id, ep):
    """æå–å½±ç‰‡ç¶²å€"""
    m3u8_links = set()
    # æ’­æ”¾é é€šå¸¸åœ¨ dramasq.io
    play_url = f"https://dramasq.io/vodplay/{drama_id}/ep{ep}.html"
    
    def handle_request(req):
        if ".m3u8" in req.url.lower():
            m3u8_links.add(req.url)

    page.on("request", handle_request)

    try:
        print(f"ğŸ¬ æ­£åœ¨è§£æç¬¬ {ep} é›†...")
        # ä½¿ç”¨ networkidle è¼ƒèƒ½ç¢ºä¿ iframe å…§çš„å½±ç‰‡è¼‰å…¥
        await page.goto(play_url, wait_until="commit", timeout=60000)
        
        # ç­‰å¾…å½±ç‰‡æ’ä»¶è¼‰å…¥
        for _ in range(15):
            if m3u8_links: break
            for frame in page.frames:
                try:
                    content = await frame.content()
                    found = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', content)
                    for link in found: m3u8_links.add(link)
                except: continue
            await asyncio.sleep(1.5)
            
        # å¦‚æœé‚„æ˜¯æ²’æ‰¾åˆ°ï¼Œå˜—è©¦é»æ“Šæ’­æ”¾å™¨å€åŸŸè§¸ç™¼è«‹æ±‚
        if not m3u8_links:
            await page.mouse.click(640, 360)
            await asyncio.sleep(5)
            
    except Exception as e:
        print(f"âš ï¸ ç¬¬ {ep} é›†è§£æç•°å¸¸: {e}")
    finally:
        page.remove_listener("request", handle_request)
        
    return list(m3u8_links)

async def run():
    async with async_playwright() as p:
        # å•Ÿå‹•ç€è¦½å™¨ (ä¿®æ­£åŸæœ¬æ¼æ‰çš„å•Ÿå‹•ç¢¼)
        browser = await p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        drama_id = None
        input_str = str(TARGET_INPUT).strip()

        # --- 1. è­˜åˆ¥è¼¸å…¥å…§å®¹ ---
        if input_str.isdigit():
            drama_id = input_str
            print(f"ğŸ”¢ ä»£ç¢¼æ¨¡å¼: {drama_id}")
        else:
            print(f"ğŸ” åŠ‡åæ¨¡å¼: æ­£åœ¨æœå°‹ã€Œ{input_str}ã€...")
            try:
                await page.goto(f"https://{DOMAIN}/all/", wait_until="domcontentloaded", timeout=60000)
                await page.wait_for_selector("a[href*='/detail/']")
                links = await page.query_selector_all("a[href*='/detail/']")
                
                for link in links:
                    text = (await link.inner_text() or "").strip()
                    title = (await link.get_attribute("title") or "").strip()
                    if input_str in text or input_str in title:
                        href = await link.get_attribute("href")
                        match = re.search(r'/detail/(\d+)\.html', href)
                        if match:
                            drama_id = match.group(1)
                            print(f"âœ… åŒ¹é…æˆåŠŸ: {text} (ID: {drama_id})")
                            break
            except Exception as e:
                print(f"âŒ æœå°‹éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

        if not drama_id:
            print(f"âŒ ç„¡æ³•è­˜åˆ¥æˆ–æ‰¾ä¸åˆ°: {TARGET_INPUT}")
            await browser.close(); return

        # --- 2. è‡ªå‹•åµæ¸¬ç¸½é›†æ•¸ ---
        detail_url = f"https://dramasq.io/detail/{drama_id}.html"
        await page.goto(detail_url, wait_until="domcontentloaded")
        
        # ç¢ºä¿é›†æ•¸åˆ—è¡¨å·²è¼‰å…¥
        try:
            await page.wait_for_selector("a[href*='/vodplay/']", timeout=10000)
            ep_links = await page.query_selector_all("a[href*='/vodplay/']")
            all_eps = []
            for l in ep_links:
                t = await l.inner_text()
                m = re.search(r'(\d+)', t)
                if m: all_eps.append(int(m.group(1)))
            
            total_ep = max(all_eps) if all_eps else 1
        except:
            total_ep = 1

        print(f"ğŸ“Š åµæ¸¬å®Œæˆï¼šå…± {total_ep} é›†ã€‚")

        # --- 3. åŸ·è¡ŒæŠ“å– ---
        output_file = "all_episodes_results.txt"
        # è®€å–ç¾æœ‰é€²åº¦
        existing_eps = set()
        if os.path.exists(output_file):
            with open(output_file, "r", encoding="utf-8") as f:
                existing_eps = set(map(int, re.findall(r'ç¬¬ (\d+) é›†', f.read())))

        for ep in range(1, total_ep + 1):
#            if ep in existing_eps:
 #               print(f"â­ï¸ ç¬¬ {ep} é›†å·²å­˜åœ¨ï¼Œè·³éã€‚")
  #              continue
                
            links = await get_m3u8_for_ep(page, drama_id, ep)
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"ç¬¬ {ep} é›†: {', '.join(links) if links else 'æœªæ‰¾åˆ°'}\n")
            
            await asyncio.sleep(random.uniform(1, 3) if 'random' in globals() else 2)

        await browser.close()
        print("ğŸ åŒæ­¥ä»»å‹™å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(run())
