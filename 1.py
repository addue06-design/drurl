import asyncio
import re
import os
import random
from playwright.async_api import async_playwright

# --- è¨­å®šå€åŸŸ ---
TARGET_ID = "5597942" 
BASE_DOMAIN = "dramaq.xyz"
# ------------------

async def get_m3u8_for_ep(page, drama_id, ep):
    m3u8_links = set()
    # æ’­æ”¾é è·¯å¾‘ï¼š/cn/5597942/1.html
    play_url = f"https://{BASE_DOMAIN}/cn/{drama_id}/{ep}.html"
    
    def handle_request(req):
        if ".m3u8" in req.url.lower():
            m3u8_links.add(req.url)
    page.on("request", handle_request)

    try:
        print(f"ğŸ¬ æ­£åœ¨è§£æç¬¬ {ep} é›†...")
        # é€™è£¡æ”¹ç”¨ wait_until="networkidle"ï¼Œç¢ºä¿å½±ç‰‡è§£æ JS è·‘å®Œ
        await page.goto(play_url, wait_until="networkidle", timeout=60000)
        
        # è¼ªè©¢æª¢æŸ¥æ‰€æœ‰ frames
        for _ in range(10):
            if m3u8_links: break
            for frame in page.frames:
                try:
                    content = await frame.content()
                    found = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', content)
                    for link in found: m3u8_links.add(link)
                except: continue
            await asyncio.sleep(2)
            
    except Exception as e:
        print(f"âš ï¸ ç¬¬ {ep} é›†è§£æç•°å¸¸: {e}")
    finally:
        page.remove_listener("request", handle_request)
    return list(m3u8_links)

async def run():
    async with async_playwright() as p:
        # å•Ÿå‹•ä¸¦åŠ å…¥å½è£åƒæ•¸
        browser = await p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        detail_url = f"https://{BASE_DOMAIN}/cn/{TARGET_ID}/"
        print(f"ğŸ“¡ å‰å¾€è©³æƒ…é : {detail_url}")
        
        await page.goto(detail_url, wait_until="domcontentloaded")
        await asyncio.sleep(5) # çµ¦äºˆè¶³å¤ æ™‚é–“è®“ JS æ¸²æŸ“æ¸…å–®

        # --- æ ¸å¿ƒåµæ¸¬é‚è¼¯ï¼šç›´æ¥æŠ“å–é é¢æ‰€æœ‰é€£çµä¸¦ç”¨æ­£å‰‡ç¯©é¸ ---
        all_eps = set()
        
        # æŠ“å–é é¢ä¸Šæ‰€æœ‰çš„ <a> æ¨™ç±¤çš„ href
        hrefs = await page.evaluate("""
            () => Array.from(document.querySelectorAll('a')).map(a => a.href)
        """)
        
        # åŒ¹é…æ ¼å¼ï¼š/cn/5597942/1.html
        pattern = rf"/{TARGET_ID}/(\d+)\.html"
        for href in hrefs:
            match = re.search(pattern, href)
            if match:
                all_eps.add(int(match.group(1)))

        if not all_eps:
            # å‚™ç”¨ï¼šå¦‚æœé€£çµæ²’å‡ºä¾†ï¼Œå¯èƒ½åœ¨æŸäº›éš±è—çš„ JSON è£¡
            print("ğŸ•µï¸ å˜—è©¦å¾åŸå§‹ç¢¼ç›´æ¥æå–é›†æ•¸æ•¸å­—...")
            content = await page.content()
            matches = re.findall(rf"/{TARGET_ID}/(\d+)\.html", content)
            all_eps.update([int(m) for m in matches])

        if not all_eps:
            print("âŒ ä¾ç„¶æ‰¾ä¸åˆ°é›†æ•¸ã€‚è«‹ç¢ºèª ID æ˜¯å¦æ­£ç¢ºï¼Œæˆ–ç¶²åŸŸæ˜¯å¦æœ‰è·³è½‰ã€‚")
            await browser.close(); return

        ep_list = sorted(list(all_eps))
        print(f"âœ… åµæ¸¬å®Œæˆï¼šæ‰¾åˆ°å…± {len(ep_list)} é›† (é›†æ•¸: {ep_list})")

        # --- åŸ·è¡ŒæŠ“å– ---
        output_file = "all_episodes_results.txt"
        for ep in ep_list:
            # æª¢æŸ¥å¢é‡
            if os.path.exists(output_file):
                with open(output_file, "r", encoding="utf-8") as f:
                    if f"ç¬¬ {ep} é›†:" in f.read():
                        print(f"â­ï¸ ç¬¬ {ep} é›†å·²å­˜åœ¨ï¼Œè·³éã€‚")
                        continue

            links = await get_m3u8_for_ep(page, TARGET_ID, ep)
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"ç¬¬ {ep} é›†: {', '.join(links) if links else 'æœªæ‰¾åˆ°'}\n")
            print(f"ğŸ’¾ ç¬¬ {ep} é›†è³‡æ–™å·²å­˜æª”")
            await asyncio.sleep(random.uniform(2, 4))

        await browser.close()
        print("ğŸ å…¨éƒ¨ä»»å‹™çµæŸ")

if __name__ == "__main__":
    asyncio.run(run())
