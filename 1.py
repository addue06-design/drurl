import asyncio
import re
import os
from playwright.async_api import async_playwright

# --- è¨­å®šå€åŸŸ ---
TARGET_INPUT = "éå‡¡"  # é€™è£¡å¯ä»¥æ”¾åŠ‡åæˆ–ä»£ç¢¼
# ------------------

async def get_m3u8_for_ep(page, drama_id, ep):
    """æå–å½±ç‰‡ç¶²å€é‚è¼¯"""
    m3u8_links = set()
    play_url = f"https://dramasq.io/vodplay/{drama_id}/ep{ep}.html"
    def handle_request(req):
        if ".m3u8" in req.url: m3u8_links.add(req.url)
    page.on("request", handle_request)
    
    try:
        print(f"ğŸ¬ æ­£åœ¨è§£æç¬¬ {ep} é›†...")
        await page.goto(play_url, wait_until="domcontentloaded", timeout=60000)
        for _ in range(15):
            for frame in page.frames:
                try:
                    content = await frame.content()
                    found = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', content)
                    for link in found: m3u8_links.add(link)
                except: continue
            if m3u8_links: break
            await asyncio.sleep(1)
    except Exception as e:
        print(f"âš ï¸ ç¬¬ {ep} é›†è§£æç•°å¸¸: {e}")
    finally:
        page.remove_listener("request", handle_request)
    return list(m3u8_links)

async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        drama_id = None
        input_str = str(TARGET_INPUT).strip()

        # --- é›™è»Œæœå°‹é‚è¼¯ ---
        if input_str.isdigit():
            drama_id = input_str
            print(f"ğŸ”¢ ä»£ç¢¼æ¨¡å¼: {drama_id}")
        else:
            print(f"ğŸ” åŠ‡åæ¨¡å¼: æ­£åœ¨å…¨åŠ‡æ¸…å–®æœå°‹ã€Œ{input_str}ã€...")
            try:
                # 1. å‰å¾€ç¸½æ¸…å–®
                await page.goto("https://dramaq.xyz/all/", wait_until="domcontentloaded", timeout=60000)
                # 2. ç¸®å°ç¯„åœï¼ŒåªæŠ“å– detail çš„ a æ¨™ç±¤
                links = await page.query_selector_all("a[href*='/detail/']")
                
                for link in links:
                    text = (await link.inner_text() or "").strip()
                    title = (await link.get_attribute("title") or "").strip()
                    href = (await link.get_attribute("href") or "")
                    
                    # 3. æ¨¡ç³Šæ¯”å°ï¼ˆå¿½ç•¥ç©ºæ ¼ï¼Œæ”¯æ´åŒ…å«é—œä¿‚ï¼‰
                    combined_source = (text + title).replace(" ", "")
                    target_clean = input_str.replace(" ", "")
                    
                    if target_clean in combined_source:
                        match = re.search(r'/detail/(\d+)\.html', href)
                        if match:
                            drama_id = match.group(1)
                            print(f"âœ… æˆåŠŸå‘½ä¸­: ã€Œ{text or title}ã€ (ID: {drama_id})")
                            break
            except Exception as e:
                print(f"âŒ æœå°‹éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

        if not drama_id:
            print(f"âŒ æœå°‹ä¸åˆ°ã€Œ{TARGET_INPUT}ã€ã€‚è«‹ç¢ºèªåŠ‡åæ˜¯å¦æ­£ç¢ºæˆ–ç›´æ¥æ”¹ç”¨ä»£ç¢¼ã€‚")
            await browser.close(); return

        # --- è‡ªå‹•åµæ¸¬ç¸½é›†æ•¸ ---
        await page.goto(f"https://dramasq.io/detail/{drama_id}.html", wait_until="domcontentloaded")
        ep_links = await page.query_selector_all("a[href*='/vodplay/']")
        all_eps = []
        for l in ep_links:
            t = await l.inner_text()
            m = re.search(r'(\d+)', t)
            if m: all_eps.append(int(m.group(1)))
        
        total_ep = max(all_eps) if all_eps else 1
        print(f"ğŸ“Š åµæ¸¬å®Œæˆï¼šå…± {total_ep} é›†ã€‚é–‹å§‹å¢é‡åŒæ­¥...")

        # å¢é‡å¯«å…¥é‚è¼¯
        existing_eps = set()
        if os.path.exists("all_episodes_results.txt"):
            with open("all_episodes_results.txt", "r", encoding="utf-8") as f:
                existing_eps = set(map(int, re.findall(r'ç¬¬ (\d+) é›†', f.read())))

        for ep in range(1, total_ep + 1):
            if ep in existing_eps:
                print(f"â­ï¸ ç¬¬ {ep} é›†å·²å­˜åœ¨ï¼Œè·³éã€‚")
                continue
            
            links = await get_m3u8_for_ep(page, drama_id, ep)
            with open("all_episodes_results.txt", "a", encoding="utf-8") as f:
                f.write(f"ç¬¬ {ep} é›†: {', '.join(links) if links else 'æœªæ‰¾åˆ°'}\n")
            await asyncio.sleep(2)

        await browser.close()
        print("ğŸ åŒæ­¥çµæŸï¼")

if __name__ == "__main__":
    asyncio.run(run())
