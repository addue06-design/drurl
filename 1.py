import asyncio
import re
import os
import random
from playwright.async_api import async_playwright

# --- è¨­å®šå€åŸŸ ---
TARGET_ID = "5597942" 
BASE_DOMAIN = "dramaq.xyz"
# ------------------

async def get_m3u8_for_ep(page, drama_id, ep):
    m3u8_links = set()
    # ä¿®æ­£æ’­æ”¾ç¶²å€ï¼šåŠ å…¥ /ep{ep}.html
    play_url = f"https://{BASE_DOMAIN}/cn/{drama_id}/ep{ep}.html"
    
    def handle_request(req):
        if ".m3u8" in req.url.lower():
            m3u8_links.add(req.url)
    page.on("request", handle_request)

    try:
        print(f"ğŸ¬ æ­£åœ¨è§£æç¬¬ {ep} é›†: {play_url}")
        # ä½¿ç”¨ networkidle ç¢ºä¿ M3U8 è«‹æ±‚ç™¼å‡º
        await page.goto(play_url, wait_until="networkidle", timeout=60000)
        
        # æƒæå¤šå±¤ frame å…§å®¹
        for _ in range(12):
            if m3u8_links: break
            for frame in page.frames:
                try:
                    content = await frame.content()
                    found = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', content)
                    for link in found: m3u8_links.add(link)
                except: continue
            await asyncio.sleep(2)
            
    except Exception as e:
        print(f"âš ï¸ ç¬¬ {ep} é›†è§£æç•°å¸¸: {e}")
    finally:
        page.remove_listener("request", handle_request)
    return list(m3u8_links)

async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        detail_url = f"https://{BASE_DOMAIN}/cn/{TARGET_ID}/"
        print(f"ğŸ“¡ å‰å¾€è©³æƒ…é : {detail_url}")
        
        await page.goto(detail_url, wait_until="domcontentloaded")
        await asyncio.sleep(5) # ç­‰å¾…åˆ—è¡¨å‹•æ…‹åŠ è¼‰

        # --- æ ¸å¿ƒåµæ¸¬é‚è¼¯ï¼šæ›´æ–°ç‚º /ep(\d+)\.html ---
        all_eps = set()
        
        # 1. å¾é é¢ç¾æœ‰é€£çµæå–
        hrefs = await page.evaluate("() => Array.from(document.querySelectorAll('a')).map(a => a.href)")
        pattern = rf"/{TARGET_ID}/ep(\d+)\.html"
        
        for href in hrefs:
            match = re.search(pattern, href)
            if match:
                all_eps.add(int(match.group(1)))

        # 2. å¦‚æœé€£çµæ²’è¢«æ¸²æŸ“ï¼Œç›´æ¥å¾åŸå§‹ç¢¼æš´åŠ›æœå°‹
        if not all_eps:
            print("ğŸ•µï¸ å˜—è©¦å¾åŸå§‹ç¢¼ç›´æ¥æå– ep æ•¸å­—...")
            content = await page.content()
            matches = re.findall(pattern, content)
            all_eps.update([int(m) for m in matches])

        if not all_eps:
            print("âŒ ä¾ç„¶æ‰¾ä¸åˆ°é›†æ•¸ã€‚è«‹ç¢ºèªè©² ID åœ¨ç¶²ç«™ä¸Šæ˜¯å¦æœ‰é›†æ•¸åˆ—è¡¨ã€‚")
            await browser.close(); return

        ep_list = sorted(list(all_eps))
        print(f"âœ… åµæ¸¬æˆåŠŸï¼šå…± {len(ep_list)} é›† (æ¸…å–®: {ep_list})")

        # --- 3. åŸ·è¡ŒæŠ“å– ---
        output_file = "all_episodes_results.txt"
        for ep in ep_list:
            # å¢é‡åˆ¤æ–·
            if os.path.exists(output_file):
                with open(output_file, "r", encoding="utf-8") as f:
                    if f"ç¬¬ {ep} é›†:" in f.read():
                        print(f"â­ï¸ ç¬¬ {ep} é›†å·²å­˜åœ¨ï¼Œè·³éã€‚")
                        continue

            links = await get_m3u8_for_ep(page, TARGET_ID, ep)
            with open(output_file, "a", encoding="utf-8") as f:
                f.write(f"ç¬¬ {ep} é›†: {', '.join(links) if links else 'æœªæ‰¾åˆ°'}\n")
            print(f"ğŸ’¾ ç¬¬ {ep} é›†è§£æå®Œæˆä¸¦è¨˜éŒ„")
            
            # å»¶æ™‚é¿å…è¢«å°é–
            await asyncio.sleep(random.uniform(2, 4))

        await browser.close()
        print("ğŸ å…¨éƒ¨åŒæ­¥ä»»å‹™å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(run())
